{"meta":{"title":"Void","subtitle":null,"description":"爱吃爱玩的程序猿，热爱生活、热爱美食、热爱运动，有理想的一笔!","author":"Zhao Xiao Dan","url":"http://localhost:4000"},"pages":[{"title":"About","date":"2018-05-22T00:26:50.132Z","updated":"2018-05-20T12:02:05.372Z","comments":true,"path":"about/index.html","permalink":"http://localhost:4000/about/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-05-22T08:31:52.960Z","updated":"2018-05-20T12:02:05.372Z","comments":true,"path":"tags/index.html","permalink":"http://localhost:4000/tags/index.html","excerpt":"","text":""},{"title":"Project","date":"2018-05-22T00:26:50.133Z","updated":"2018-05-20T12:02:05.372Z","comments":true,"path":"project/index.html","permalink":"http://localhost:4000/project/index.html","excerpt":"","text":""}],"posts":[{"title":"深入剖析Java中的装箱和拆箱","slug":"深入剖析Java中的装箱和拆箱","date":"2018-07-18T03:17:03.000Z","updated":"2018-07-18T03:17:49.128Z","comments":true,"path":"2018/07/18/深入剖析Java中的装箱和拆箱/","link":"","permalink":"http://localhost:4000/2018/07/18/深入剖析Java中的装箱和拆箱/","excerpt":"","text":"深入剖析Java中的装箱和拆箱","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://localhost:4000/tags/java/"},{"name":"装箱和拆箱","slug":"装箱和拆箱","permalink":"http://localhost:4000/tags/装箱和拆箱/"}]},{"title":"spring cloud概述，为何使用spring cloud","slug":"spring cloud概述，为何使用spring cloud","date":"2018-07-11T07:30:22.000Z","updated":"2018-07-11T07:32:20.841Z","comments":true,"path":"2018/07/11/spring cloud概述，为何使用spring cloud/","link":"","permalink":"http://localhost:4000/2018/07/11/spring cloud概述，为何使用spring cloud/","excerpt":"","text":"spring cloud概述，为何使用spring cloud","categories":[],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://localhost:4000/tags/springcloud/"}]},{"title":"面试","slug":"面试","date":"2018-07-10T09:49:21.000Z","updated":"2018-07-11T08:26:35.229Z","comments":true,"path":"2018/07/10/面试/","link":"","permalink":"http://localhost:4000/2018/07/10/面试/","excerpt":"","text":"2、Map 的底层结构？（HashMap） 3、线程安全的 Map （concurrentHashMap）简单的说了下这两 1。7 和 1.8 的区别，本想问下要不要深入的讲下（源码级别），结果面试官说不用了。谈谈ConcurrentHashMap1.7和1.8的不同实现ConcurrentHashMap从jdk1.7到jdk1.8的变化 4、项目 MySQL 的数据量和并发量有多大？MySQL到底能支持多大的数据量？ 5、你对数据库了解多少？对几种数据库的认识数据库你了解多少 6、你说下数据库的索引实现和非主键的二级索引索引的实现原理 7、项目用的是 SpringBoot ，你能说下 Spring Boot 与 Spring 的区别吗？springmvc和springboot的区别springboot和spring 的区别 8、SpringBoot 的自动配置是怎么做的？SpringBoot实战之SpringBoot自动配置原理SpringBoot自动配置原理 9、MyBatis 定义的接口，怎么找到实现的？ 10、Java 内存结构 11、对象是否可 GC？ 12、Minor GC 和 Full GC 13、垃圾回收算法 14、垃圾回收器 G1 15、项目里用过 ElasticSearch 和 Hbase，有深入了解他们的调优技巧吗？ 16、Spring RestTemplate 的具体实现 17、描述下网页一个 Http 请求，到后端的整个请求过程 18、多线程的常用方法和接口类及线程池的机制 19、总结我的 Java 基础还是不错，但是一些主流的框架源码还是处在使用的状态，需要继续去看源码 20、死锁 1、HashMap，源码级别的问了，包括为什么线程不安全 2、死锁 3、Synchronized 和 ReentrantLock 锁机制，怎么判断重入锁的，会不会是死锁？ 4、进程和线程的区别？ 5、进程之间如何保证同步？ 6、分布式锁 7、对象 GC 8、垃圾回收算法 9、JVM 参数 10、OOM 出现的有哪些场景？为什么会发生？ 11、JVM 内存结构说下吧 12、堆和栈的共享问题？ 13、有比较过 Http 和 RPC 吗？ 14、HttpClient 你说说里面的具体实现吧？（涉及了哪些东西） 15、那要你设计一个高性能的 Http ，你会怎么设计？","categories":[],"tags":[]},{"title":"Hexo 图片本地存储","slug":"Hexo 图片本地存储","date":"2018-07-10T02:50:15.000Z","updated":"2018-07-10T03:47:03.708Z","comments":true,"path":"2018/07/10/Hexo 图片本地存储/","link":"","permalink":"http://localhost:4000/2018/07/10/Hexo 图片本地存储/","excerpt":"","text":"由于hexo发布博客必须是markdown格式，写起来真的是太太太麻烦了，想到在CSDN发布博客时采用markdown编辑器，左右两边相互对照，很是方便，又有导出文件到本地的功能，因此每次在发布博客时我都采取懒人办法… 利用csdn提供的在线markdown编辑器发布博客 正常编辑、发布文章 编辑好后将文件导出到本地 将导出的md文件放在hexo网站所在位置下的source_posts目录，这个目录下存储了很多个md文件，每个文件对应着一篇博客。 在博客站点文件夹下空白处点击右键，选择Git Bash Here，输入：hexo g，生成静态页面，再输入：hexo server，到localhost:4000预览博客效果，最后输入：hexo d，部署； 第四步可简单输入命令：hexo d -g 解决利用csdn发布博客图片不显示的问题1、 将主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true； 2、在hexo目录下执行npm install hexo-asset-image --save，这是下载安装一个可以上传本地图片的插件； 3、稍等片刻，再运行hexo n &quot;xxxx&quot;来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 4、 在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片： ![这里输入图片描述](/xxxx/图片名.jpg) *注意： 此处xxxx代表的是新建博文md文件的名字，也是同名文件夹的名字 如下图： 具体引入路径如下： /Hexo快速发布博文及插入图片/图片显示问题.png 这样就可以解决图片不显示的问题啦~~~~","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://localhost:4000/tags/hexo/"},{"name":"图片存储","slug":"图片存储","permalink":"http://localhost:4000/tags/图片存储/"}]},{"title":"B+树","slug":"B+树","date":"2018-07-05T01:08:14.000Z","updated":"2018-07-05T02:53:42.477Z","comments":true,"path":"2018/07/05/B+树/","link":"","permalink":"http://localhost:4000/2018/07/05/B+树/","excerpt":"","text":"原文地址：https://www.cnblogs.com/wade-luffy/p/6292784.html B+树B+树和二叉树、平衡二叉树一样，都是经典的数据结构。B+树由B树和索引顺序访问方法（ISAM，是不是很熟悉？对，这也是MyISAM引擎最初参考的数据结构）演化而来，但是在实际使用过程中几乎已经没有使用B树的情况了。 B+树的定义十分复杂，因此只简要地介绍B+树：B+树是为磁盘或其他直接存取辅助设备而设计的一种平衡查找树，在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶节点中，各叶节点指针进行连接。 我们先来看一个B+树，其高度为2，每页可存放4条记录，扇出（fan out）为5。 可以看出，所有记录都在叶节点中，并且是顺序存放的，如果我们从最左边的叶节点开始顺序遍历，可以得到所有键值的顺序排序：5、10、15、20、25、30、50、55、60、65、75、80、85、90。 B+树的插入操作B+树的插入必须保证插入后叶节点中的记录依然排序，同时需要考虑插入B+树的三种情况，每种情况都可能会导致不同的插入算法，如表5-1所示。 我们用实例来分析B+树的插入，我们插入28这个键值，发现当前Leaf Page和Index Page都没有满，我们直接插入就可以了。 这次我们再插入一条70这个键值，这时原先的Leaf Page已经满了，但是Index Page还没有满，符合表5-1的第二种情况，这时插入Leaf Page后的情况为50、55、60、65、70。我们根据中间的值60拆分叶节点。 因为图片显示的关系，这次我没有能在各叶节点加上双向链表指针。最后我们来插入记录95，这时符合表5-1讨论的第三种情况，即Leaf Page和Index Page都满了，这时需要做两次拆分。 可以看到，不管怎么变化，B+树总是会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页（split）操作，而B+树主要用于磁盘，因此页的拆分意味着磁盘的操作，应该在可能的情况下尽量减少页的拆分。因此，B+树提供了旋转（rotation）的功能。 旋转发生在Leaf Page已经满了、但是其左右兄弟节点没有满的情况下。这时B+树并不会急于去做拆分页的操作，而是将记录移到所在页的兄弟节点上。通常情况下，左兄弟被首先检查用来做旋转操作，这时我们插入键值70，其实B+树并不会急于去拆分叶节点，而是做旋转，50，55，55旋转。 可以看到，采用旋转操作使B+树减少了一次页的拆分操作，而这时B+树的高度依然还是2。 B+树的删除操作B+树使用填充因子（fill factor）来控制树的删除变化，50%是填充因子可设的最小值。B+树的删除操作同样必须保证删除后叶节点中的记录依然排序，同插入一样，B+树的删除操作同样需要考虑如表5-2所示的三种情况，与插入不同的是，删除根据填充因子的变化来衡量。 首先，删除键值为70的这条记录，该记录符合表5-2讨论的第一种情况，删除后。 接着我们删除键值为25的记录，这也是表5-2讨论的第一种情况，但是该值还是Index Page中的值，因此在删除Leaf Page中25的值后，还应将25的右兄弟节点的28更新到Page Index中，最后可得到图。 最后我们来看删除键值为60的情况，删除Leaf Page中键值为60的记录后，填充因子小于50%，这时需要做合并操作，同样，在删除Index Page中相关记录后需要做Index Page的合并操作，最后得到图。","categories":[],"tags":[{"name":"B+树","slug":"B-树","permalink":"http://localhost:4000/tags/B-树/"},{"name":"ISAM","slug":"ISAM","permalink":"http://localhost:4000/tags/ISAM/"}]},{"title":"二叉树遍历（前序、后序、中序）","slug":"二叉树遍历（前序、后序、中序）","date":"2018-07-04T00:40:47.000Z","updated":"2018-07-10T09:01:19.869Z","comments":true,"path":"2018/07/04/二叉树遍历（前序、后序、中序）/","link":"","permalink":"http://localhost:4000/2018/07/04/二叉树遍历（前序、后序、中序）/","excerpt":"","text":"二叉树遍历：从树的根节点出发，按照某种次序依次访问二叉树中所有的结点，使得每个结点被访问仅且一次。 这里有两个关键词：**访问**和**次序**。 1. 前序遍历基本思想：先访问根结点，再先序遍历左子树，最后再先序遍历右子树即根—左—右。 2. 中序遍历基本思想：先中序遍历左子树，然后再访问根结点，最后再中序遍历右子树即左—根—右。 3. 后序遍历基本思想：先后序遍历左子树，然后再后序遍历右子树，最后再访问根结点即左—右—根。","categories":[],"tags":[{"name":"二叉树遍历","slug":"二叉树遍历","permalink":"http://localhost:4000/tags/二叉树遍历/"}]},{"title":"SQL性能优化","slug":"SQL性能优化","date":"2018-07-04T00:37:49.000Z","updated":"2018-07-11T03:45:51.566Z","comments":true,"path":"2018/07/04/SQL性能优化/","link":"","permalink":"http://localhost:4000/2018/07/04/SQL性能优化/","excerpt":"","text":"1.查询的模糊匹配尽量避免在一个复杂查询里面使用 LIKE &apos;%parm1%&apos;—— 红色标识位置的百分号会导致相关列的索引无法使用，最好不要用. 解决办法:其实只需要对该脚本略做改进，查询速度便会提高近百倍。改进方法如下： a、修改前台程序——把查询条件的供应商名称一栏由原来的文本输入改为下拉列表，用户模糊输入供应商名称时，直接在前台就帮忙定位到具体的供应商，这样在调用后台程序时，这列就可以直接用等于来关联了。 b、直接修改后台——根据输入条件，先查出符合条件的供应商，并把相关记录保存在一个临时表里头，然后再用临时表去做复杂关联 2.索引问题在做性能跟踪分析过程中，经常发现有不少后台程序的性能问题是因为缺少合适索引造成的，有些表甚至一个索引都没有。这种情况往往都是因为在设计表时，没去定义索引，而开发初期，由于表记录很少，索引创建与否，可能对性能没啥影响，开发人员因此也未多加重视。然一旦程序发布到生产环境，随着时间的推移，表记录越来越多，这时缺少索引，对性能的影响便会越来越大了。 这个问题需要数据库设计人员和开发人员共同关注 法则：不要在建立的索引的数据列上进行下列操作:避免对索引字段进行计算操作避免在索引字段上使用not，&lt;&gt;，!=避免在索引列上使用IS NULL和IS NOT NULL避免在索引列上出现数据类型转换避免在索引字段上使用函数避免建立索引的列中使用空值。 3.复杂操作部分UPDATE、SELECT 语句 写得很复杂（经常嵌套多级子查询）——可以考虑适当拆成几步，先生成一些临时数据表，再进行关联操作 4.update同一个表的修改在一个过程里出现好几十次，如： update table1 set col1=… where col2=…; update table1 set col1=... where col2=... ...... 象这类脚本其实可以很简单就整合在一个UPDATE语句来完成（前些时候在协助xxx项目做性能问题分析时就发现存在这种情况） 5.在可以使用UNION ALL的语句里，使用了UNIONUNION 因为会将各查询子集的记录做比较，故比起UNION ALL ，通常速度都会慢上许多。一般来说，如果使用UNION ALL能满足要求的话， 务必使用UNION ALL。还有一种情况大家可能会忽略掉，就是虽然要求几个子集的并集需要过滤掉重复记录，但由于脚本的特殊性，不可能存在重复记录，这时便应该使用UNION ALL，如xx模块的某个查询程序就曾经存在这种情况，见，由于语句的特殊性，在这个脚本 中几个子集的记录绝对不可能重复，故可以改用UNION ALL） 6.在WHERE 语句中，尽量避免对索引字段进行计算操作这个常识相信绝大部分开发人员都应该知道，但仍有不少人这么使用，我想其中一个最主要的原因可能是为了编写方便吧，但如果仅为了编 写简单而损害了性能，那就不可取了 9月份在对XX系统做性能分析时发现，有大量的后台程序存在类似用法，如： ...... where trunc(create_date)=trunc(:date1) 虽然已对create_date 字段建了索引，但由于加了TRUNC，使得索引无法用上。此处正确的写法应该是 where create\\_date&gt;=trunc(:date1) and create\\_date&lt;trunc(:date1)+1 或者是 where create_date between trunc(:date1) and trunc(:date1)+1-1/(24\\*60\\*60) 注意：因between 的范围是个闭区间（greater than or equal to low value and less than or equal to high value.）， 故严格意义上应该再减去一个趋于0的小数，这里暂且设置成减去1秒（1/(24\\*60\\*60)），如果不要求这么精确的话，可以略掉这步 7.对Where 语句的法则7.1 避免在WHERE子句中使用in，not in，or 或者having。可以使用 exist 和not exist代替 in和not in。可以使用表链接代替 exist。Having可以用where代替，如果无法代替可以分两步处理。例子SELECT FROM ORDERS WHERE CUSTOMER_NAME NOT IN (SELECT CUSTOMER_NAME FROM CUSTOMER)优化SELECT FROM ORDERS WHERE CUSTOMER_NAME not exist (SELECT CUSTOMER_NAME FROM CUSTOMER) 7.2 不要以字符格式声明数字，要以数字格式声明字符值。（日期同样）**否则会使索引无效，产生全表扫描。例子使用：SELECT emp.ename, emp.job FROM emp WHERE emp.empno = 7369;不要使用：SELECT emp.ename, emp.job FROM emp WHERE emp.empno = ‘7369’ 7.3 WHERE后面的条件顺序影响 Oracle从下到上处理Where子句中多个查询条件，所以表连接语句应写在其他Where条件前，可以过滤掉最大数量记录的条件必须写在Where子句的末尾。 WHERE子句后面的条件顺序对大数据量表的查询会产生直接的影响，如 Select * from zl\\_yhjbqk where dy\\_dj = &apos;1KV以下&apos; and xh_bz=1 Select * from zl\\_yhjbqk where xh\\_bz=1 and dy_dj = &apos;1KV以下&apos; 以上两个SQL中dy\\_dj（电压等级）及xh\\_bz（销户标志）两个字段都没进行索引，所以执行的时候都是全表扫描，第一条SQL的dy\\_dj = &apos;1KV以下&apos;条件在记录集内比率为99%，而xh\\_bz=1的比率只为0.5%，在进行第一条SQL的时候99%条记录都进行dy\\_dj及xh\\_bz的比较，而在进行第二条SQL的时候0.5%条记录都进行dy\\_dj及xh\\_bz的比较，以此可以得出第二条SQL的CPU占用率明显比第一条低。 8.对Select语句的法则在应用程序、包和过程中限制使用select * from table这种方式。 例子使用SELECT empno,ename,category FROM emp WHERE empno = ‘7369‘而不要使用SELECT * FROM emp WHERE empno = ‘7369’ 9. 排序避免使用耗费资源的操作带有DISTINCT,UNION,MINUS,INTERSECT,ORDER BY的SQL语句会启动SQL引擎 执行，耗费资源的排序(SORT)功能. DISTINCT需要一次排序操作, 而其他的至少需要执行两次排序 10.临时表慎重使用临时表可以极大的提高系统性能 11.ORDER BYORDER BY 子句只在两种严格的条件下使用索引.ORDER BY中所有的列必须包含在相同的索引中并保持在索引中的排列顺序.ORDER BY中所有的列必须定义为非空. 12.SQL书写的影响（共享SQL语句可以提高操作效率）同一功能同一性能不同写法SQL的影响 如一个SQL在A程序员写的为 Select * from zl_yhjbqk B程序员写的为 Select * from dlyx.zl_yhjbqk（带表所有者的前缀） C程序员写的为 Select * from DLYX.ZLYHJBQK（大写表名） D程序员写的为 Select * from DLYX.ZLYHJBQK（中间多了空格） 以上四个SQL在ORACLE分析整理之后产生的结果及执行的时间是一样的，但是从ORACLE共享内存SGA的原理，可以得出ORACLE对每个SQL 都会对其进行一次分析，并且占用共享内存，如果将SQL的字符串及格式写得完全相同则ORACLE只会分析一次，共享内存也只会留下一次的分析结果，这不仅可以减少分析SQL的时间，而且可以减少共享内存重复的信息，ORACLE也可以准确统计SQL的执行频率。 推荐方案：不同区域出现的相同的Sql语句，要保证查询字符完全相同，以利用SGA共享池，防止相同的Sql语句被多次分析。 1.对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 2.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null最好不要给数据库留NULL，尽可能的使用 NOT NULL填充数据库. 备注、描述、评论之类的可以设置为 NULL，其他的，最好不要使用NULL。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num = 0 3.应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描。 4.应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or Name = ‘admin’可以这样查询： select id from t where num = 10union allselect id from t where Name = ‘admin’ 5.in 和 not in 也要慎用，否则会导致全表扫描，如： select id from t where num in(1,2,3)对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3很多时候用 exists 代替 in 是一个好的选择： select num from a where num in(select num from b)用下面的语句替换： select num from a where exists(select 1 from b where num=a.num) 6.下面的查询也将导致全表扫描： select id from t where name like ‘%abc%’若要提高效率，可以考虑全文检索。 7.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num = @num可以改为强制查询使用索引： select id from t with(index(索引名)) where num = @num.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where num/2 = 100应改为: select id from t where num = 100*2 9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3) = ’abc’ -–name以abc开头的idselect id from t where datediff(day,createdate,’2005-11-30′) = 0 -–‘2005-11-30’ –生成的id应改为: select id from t where name like ‘abc%’select id from t where createdate &gt;= ‘2005-11-30’ and createdate &lt; ‘2005-12-1’ 10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 12.不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：create table #t(…) 13.Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志。 14.对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差。 15.select count(*) from table；这样不带任何条件的count会引起全表扫描，并且没有任何业务意义，是一定要杜绝的。 16.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。 17.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 18.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连 接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 19.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 20.任何地方都不要使用 select from t ，用具体的字段列表代替“”，不要返回用不到的任何字段。 21.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 避免频繁创建和删除临时表，以减少系统表资源的消耗。临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。 23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 27.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 29.尽量避免大事务操作，提高系统并发能力。 30.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 实际案例分析：拆分大的 DELETE 或INSERT 语句，批量提交SQL语句 如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的，表一锁住了，别的操作都进不来了。 Apache 会有很多的子进程或线程。所以，其工作起来相当有效率，而我们的服务器也不希望有太多的子进程，线程和数据库链接，这是极大的占服务器资源的事情，尤其是内存。 如果你把你的表锁上一段时间，比如30秒钟，那么对于一个有很高访问量的站点来说，这30秒所积累的访问进程/线程，数据库链接，打开的文件数，可能不仅仅会让你的WEB服务崩溃，还可能会让你的整台服务器马上挂了。 所以，如果你有一个大的处理，你一定把其拆分，使用 LIMIT oracle(rownum),sqlserver(top)条件是一个好的方法。下面是一个mysql示例： 复制代码while(1){ //每次只做1000条 mysql_query(“delete from logs where log_date &lt;= ’2012-11-01’ limit 1000”); if(mysql_affected_rows() == 0){ //删除完成，退出！ break； } //每次暂停一段时间，释放表让其他进程/线程访问。usleep(50000) }","categories":[],"tags":[]},{"title":"索引以及索引的数据结构","slug":"索引以及索引的数据结构","date":"2018-07-04T00:37:22.000Z","updated":"2018-07-04T00:37:22.381Z","comments":true,"path":"2018/07/04/索引以及索引的数据结构/","link":"","permalink":"http://localhost:4000/2018/07/04/索引以及索引的数据结构/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"HashMap 实现原理（Java 8）","slug":"HashMap 实现原理","date":"2018-07-04T00:33:04.000Z","updated":"2018-07-11T07:35:05.172Z","comments":true,"path":"2018/07/04/HashMap 实现原理/","link":"","permalink":"http://localhost:4000/2018/07/04/HashMap 实现原理/","excerpt":"","text":"原文地址：HashMap实现原理及源码分析 HashMap实现原理HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。 //HashMap的主干数组，可以看到就是一个Entry数组，初始值为空数组&#123;&#125;，主干数组的长度一定是2的次幂，至于为什么这么做，后面会有详细分析。transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; Entry是HashMap中的一个静态内部类。代码如下static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next;//存储指向下一个Entry的引用，单链表结构 int hash;//对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; 所以，HashMap的整体结构如下 简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 HashMap 作为一种容器类型，无论你是否了解过其内部的实现原理，它的大名已经频频出现在各种互联网面试中了。从基本的使用角度来说，它很简单，但从其内部的实现来看（尤其是 Java 8 的改进以来），它又并非想象中那么容易。如果你一定要问了解其内部实现与否对于写程序究竟有多大影响，我不能给出一个确切的答案。但是作为一名合格程序员，对于这种遍地都在谈论的技术不应该不为所动。本篇文章主要从 jdk 1.8 的版本初步探寻 HashMap 的基本实现情况，主要涉及内容如下： HashMap 的基本组成成员 put 方法的具体实现 remove 方法的具体实现 其他一些基本方法的基本介绍 一、HashMap 的基本组成成员 首先，HashMap 是 Map 的一个实现类，它代表的是一种键值对的数据存储形式。Key 不允许重复出现，Value 随意。jdk 8 之前，其内部是由数组+链表来实现的，而 jdk 8 对于链表长度超过 8 的链表将转储为红黑树。大致的数据存储形式如下： 下面分别对其中的基本成员属性进行说明： //默认的容量，即默认的数组长度 16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //最大的容量，即数组可定义的最大长度 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; 这就是上述提到的数组，数组的元素都是 Node 类型，数组中的每个 Node 元素都是一个链表的头结点，通过它可以访问连接在其后面的所有结点。其实你也应该发现，上述的容量指的就是这个数组的长度。 transient Node&lt;K,V&gt;[] table; //实际存储的键值对个数 transient int size; //用于迭代防止结构性破坏的标量 transient int modCount; 下面这三个属性是相关的，threshold 代表的是一个阈值，通常小于数组的实际长度。伴随着元素不断的被添加进数组，一旦数组中的元素数量达到这个阈值，那么表明数组应该被扩容而不应该继续任由元素加入。而这个阈值的具体值则由负载因子（loadFactor）和数组容量来决定，公式：threshold = capacity * loadFactor。 int threshold; final float loadFactor; //HashMap 中默认负载因子为 0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; 好了，有关 HashMap 的基本属性大致介绍如上。下面我们看看它的几个重载的构造函数。 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } 这是一个最基本的构造函数，需要调用方传入两个参数，initialCapacity 和 loadFactor。程序的大部分代码在判断传入参数的合法性，initialCapacity 小于零将抛出异常，大于 MAXIMUM_CAPACITY 将被限定为 MAXIMUM_CAPACITY。loadFactor 如果小于等于零或者非数字类型也会抛出异常。 整个构造函数的核心在对 threshold 的初始化操作： static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } 这是一个小巧但精妙的方法，这里通过异或的位运算将两个字节的 n 打造成比 cap 大但最接近 2 的 n 次幂的一个数值。例如： 这里我们表示 n 的时候使用了 7 个 x，所以无论 x 为 0 或者 1，n 的值都是大于 2 的 7 次幂的。我们从最终结果可以看到，最后的 n 被打造为 8 个 1，也就是 2 的 8 次幂减一。 所以从宏观上看，传入的容量无论是处于任何范围，最终都会被打造成比该值大并且比最近的一个 2 的 n 次幂小一的值。为什么这么做？因为 2 的 n 次幂小一的值在二进制角度看全为 1，将有利于 HashMap 中的元素搜索，这一点我们后续将介绍。 那么通过该方法，我们将获得一个 2 的整数次幂的容量的值，此处存放至 threshold，实际上我们获取的是一个有关数组容量的值，不应该存放至阈值 threshold 中，但在后续实际初始化数组的时候并不会受到影响，这里可能是写 jdk 的大神偷了一次懒吧。 那么我们对于这个最基本的构造函数的介绍就已经结束了，当然，HashMap 中还有很多的重载构造函数，但几乎都是基于上述的构造函数的。例如： public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; } 最后需要说明一点的是，以上的一些构造函数都没有直接的创建一个切实存在的数组，他们都是在为创建数组需要的一些参数做初始化，所以有些在构造函数中并没有被初始化的属性都会在实际初始化数组的时候用默认值替换。 二、put 方法的具体实现 put 方法的源码分析是本篇的一个重点，因为通过该方法我们可以窥探到 HashMap 在内部是如何进行数据存储的，所谓的数组+链表+红黑树的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。带着一系列的疑问，我们看这个 put 方法： public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 添加一个元素只需要传入一个键和一个值即可，putVal 方法是关键，我已经在该方法中进行了基本的注释，具体的细节稍后详细说明，先从这些注释中大体上建立一个直观的感受。 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果 table 还未被初始化，那么初始化它 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //根据键的 hash 值找到该键对应到数组中存储的索引 //如果为 null，那么说明此索引位置并没有被占用 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //不为 null，说明此处已经被占用，只需要将构建一个节点插入到这个链表的尾部即可 else { Node&lt;K,V&gt; e; K k; //当前结点和将要插入的结点的 hash 和 key 相同，说明这是一次修改操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果 p 这个头结点是红黑树结点的话，以红黑树的插入形式进行插入 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //遍历此条链表，将构建一个节点插入到该链表的尾部 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //如果插入后链表长度大于等于 8 ，将链表裂变成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; } //遍历的过程中，如果发现与某个结点的 hash和key，这依然是一次修改操作 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } //e 不是 null，说明当前的 put 操作是一次修改操作并且e指向的就是需要被修改的结点 if (e != null) { V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; //如果添加后，数组容量达到阈值，进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; } 从整体上来看，该方法的大致处理逻辑已如上述注释说明，下面我们针对其中的细节进行详细的解释。 首先，我们看 resize 这个方法是如何对 table 进行初始化的，代码比较多，分两部分进行解析： //第一部分 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; //拿到旧数组的长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //说明旧数组已经被初始化完成了，此处需要给旧数组扩容 if (oldCap &gt; 0) { //极限的限定，达到容量限定的极限将不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } //未达到极限，将数组容量扩大两倍，阈值也扩大两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; } //数组未初始化，但阈值不为 0，为什么不为 0 ？ //上述提到 jdk 大神偷懒的事情就指的这，构造函数根据传入的容量打造了一个合适的数组容量暂存在阈值中 //这里直接使用 else if (oldThr &gt; 0) newCap = oldThr; //数组未初始化并且阈值也为0，说明一切都以默认值进行构造 else { newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } //这里也是在他偷懒的后续弥补 //newCap = oldThr 之后并没有计算阈值，所以 newThr = 0 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; ****************后续代码......******* 这一部分代码结束后，无论是初始化数组还是扩容，总之，必需的数组容量和阈值都已经计算完成了。下面看后续的代码： ************第一部分代码.....************ //根据新的容量初始化一个数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //旧数组不为 null，这次的 resize 是一次扩容行为 if (oldTab != null) { //将旧数组中的每个节点位置相对静止地拷贝值新数组中 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; //获取头结点 if ((e = oldTab[j]) != null) { oldTab[j] = null; //说明链表或者红黑树只有一个头结点，转移至新表 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果 e 是红黑树结点，红黑树分裂，转移至新表 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //这部分是将链表中的各个节点原序地转移至新表中，我们后续会详细说明 else { Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } //不论你是扩容还是初始化，都可以返回 newTab return newTab; 对于第二部分的代码段来说，主要完成的是将旧链表中的各个节点按照原序地复制到新数组中。关于头结点是红黑树的情况我们暂时不去涉及，下面重点介绍下链表的拷贝和优化代码块，这部分代码不再重复贴出，此处直接进行分析，有需要的可以参照上述列出的代码块或者自己的 jdk 进行理解。 这部分其实是一个优化操作，将当前链表上的一些结点移出来向刚扩容的另一半存储空间放。 一般我们有如下公式： index = e.hash &amp; (oldCap - 1) 随便举个例子，此时的 e 在容量扩大两倍以后的索引值没有变化，所以这部分结点是不需要移动的，那么程序如何判断扩容前后的 index 是否相等呢？ //oldCap 一定是 100...000 的形式 if ((e.hash &amp; oldCap) == 0) 如果原 oldCap 为 10000 的话，那么扩容后的 newCap 则为 100000，会比原来多出一位。所以我们只要知道原索引值的前一位是 0 还是 1 即可，如果是 0，那么它和新容量与后还是 0 并不改变索引的值，如果是 1 的话，那么索引值会增加 oldCap。 这样就分两步拆分当前链表，一条链表是不需要移动的，依然保存在当前索引值的结点上，另一条则需要变动到 index + oldCap 的索引位置上。 这里我们只介绍了普通链表的分裂情况，至于红黑树的裂变其实是类似的，依然分出一些结点到 index + oldCap 的索引位置上，只不过遍历的方式不同而已。 这样，我们对于 resize 这个扩容的方法已经解析完成了，下面接着看 putVal 方法，篇幅比较长，该方法的源码已经在介绍 resize 之前贴出，建议读者根据自己的 jdk 对照着理解。 上面我们说到，如果在 put 一个元素的时候判断内部的 table 数组还未初始化，那么调用 resize 根据相应的参数信息初始化数组。接下来的这个判断语句就很简单了： if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); 根据键的 hash 值找到对应的索引位置，如果该位置为 null，说明还没有头结点，于是 newNode 并存储在该位置上。 否则的话说明该位置已经有头结点了，或者说已经存在一个链表或红黑树了，那么我们要做的只是新建一个节点添加到链表或者红黑树的最后位置即可。 第一步， if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; p 指向当前节点，如果我们要插入的节点的键以及键所对应的 hash 值和 p 节点完全一样的话，那么说明这次 put 是一次修改操作，新建一个引用指向这个需要修改的节点。 第二步， else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); 如果当前 p 节点是红黑树结点，那么需要调用不同于链表的的添加节点的方法来添加一个节点到红黑树中。（主要是维持平衡，建议读者去了解下红黑树，此处没有深谈是限于它的复杂度和文章篇幅）。 第三步， else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp;((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } 这里主要处理的是向普通链表的末尾添加一个新的结点，e 不断地往后移动，如果发现 e 为 null，那么说明已经到链表的末尾了，那么新建一个节点添加到链表的末尾即可，因为 p 是 e 的父节点，所以直接让 p.next 指向新节点即可。添加之后，如果发现链表长度超过 8，那么将链表转储成红黑树。 在遍历的过程中，如果发现 e 所指向的当前结点和我们即将插入的节点信息完全匹配，那么也说明这是一次修改操作，由于 e 已经指向了该需要被修改的结点，所以直接 break 即可。 那么最终，无论是第一步中找到的头节点即需要被修改的节点，还是第三步在遍历中找到的需要被修改的节点，它们的引用都是 e，此时我们只需要用传入的 Value 值替换 e 指向的节点的 value 即可。正如这段代码一样： if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } 如果 e 为 null，那更简单了，说明此次 put 是添加新元素并且新元素也已经在上述代码中被添加到 HashMap 中了，我们只需要关心下，新加入一个元素后是否达到数组的阈值，如果是则调用 resize 方法扩大数组容量。该方法已经详细阐述过，此处不再赘述。 所以，这个 put 方法是集添加与修改一体的一个方法，如果执行的是添加操作则会返回 null，是修改操作则会返回旧结点的 value 值。 那么至此，我们对添加操作的内部实现想必已经了解的不错了，接下来看看删除操作的内部实现。 三、remove 方法的具体实现 删除操作就是一个查找+删除的过程，相对于添加操作其实容易一些，但那是你基于上述添加方法理解的不错的前提下。 public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } 根据键值删除指定节点，这是一个最常见的操作了。显然，removeNode 方法是核心。 final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||(value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 删除操作需要保证在表不为空的情况下进行，并且 p 节点根据键的 hash 值对应到数组的索引，在该索引处必定有节点，如果为 null ，那么间接说明此键所对应的结点并不存在于整个 HashMap 中，这是不合法的，所以首先要在这两个大前提下才能进行删除结点的操作。 第一步， if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; 需要删除的结点就是这个头节点，让 node 引用指向它。否则说明待删除的结点在当前 p 所指向的头节点的链表或红黑树中，于是需要我们遍历查找。 第二步， else if ((e = p.next) != null) { if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { do { if (e.hash == hash &amp;&amp;((k = e.key) == key ||(key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } 如果头节点是红黑树结点，那么调用红黑树自己的遍历方法去得到这个待删结点。否则就是普通链表，我们使用 do while 循环去遍历找到待删结点。找到节点之后，接下来就是删除操作了。 第三步， if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||(value != null &amp;&amp; value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } 删除操作也很简单，如果是红黑树结点的删除，直接调用红黑树的删除方法进行删除即可，如果是待删结点就是一个头节点，那么用它的 next 结点顶替它作为头节点存放在 table[index] 中，如果删除的是普通链表中的一个节点，用该结点的前一个节点直接跳过该待删结点指向它的 next 结点即可。 最后，如果 removeNode 方法删除成功将返回被删结点，否则返回 null。 这样，相对复杂的 put 和 remove 方法的内部实现，我们已经完成解析了。下面看看其他常用的方法实现，它们或多或少都于这两个方法有所关联。 四、其他常用的方法介绍 除了常用的 put 和 remove 两个方法外，HashMap 中还有一些好用的方法，下面我们简单的学习下它们。 1、clear public void clear() { Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) { size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; } } 该方法调用结束后将清除 HashMap 中存储的所有元素。 2、keySet //实例属性 keySet transient volatile Set&lt;K&gt; keySet; public Set&lt;K&gt; keySet() { Set&lt;K&gt; ks; return (ks = keySet) == null ? (keySet = new KeySet()) : ks; } final class KeySet extends AbstractSet&lt;K&gt; { public final int size() { return size; } public final void clear() { HashMap.this.clear(); } public final Iterator&lt;K&gt; iterator() { return new KeyIterator(); } public final boolean contains(Object o) { return containsKey(o); } public final boolean remove(Object key) { return removeNode(hash(key), key, null, false, true) != null; } public final Spliterator&lt;K&gt; spliterator() { return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0); } } HashMap 中定义了一个 keySet 的实例属性，它保存的是整个 HashMap 中所有键的集合。上述所列出的 KeySet 类是 Set 的一个实现类，它负责为我们提供有关 HashMap 中所有对键的操作。 可以看到，KeySet 中的所有的实例方法都依赖当前的 HashMap 实例，也就是说，我们对返回的 keySet 集中的任意一个操作都会直接映射到当前 HashMap 实例中，例如你执行删除一个键的操作，那么 HashMap 中将会少一个节点。 3、values public Collection&lt;V&gt; values() { Collection&lt;V&gt; vs; return (vs = values) == null ? (values = new Values()) : vs; } values 方法其实和 keySet 方法类似，它返回了所有节点的 value 属性所构成的 Collection 集合，此处不再赘述。 4、entrySet public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() { Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new EntrySet()) : es; } 它返回的是所有节点的集合，或者说是所有的键值对集合。 5、get public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } get 方法的内部实现其实是我们介绍过的 put 方法中的一部分，所以此处也不再赘述。 至此，我们简单的解析了 HashMap 的内部实现，虽然说并没有面面俱到，但是最基本的、最核心的部分应该是叙述清晰的。总结不到之处，望不吝赐教！","categories":[],"tags":[{"name":"HashMap实现原理","slug":"HashMap实现原理","permalink":"http://localhost:4000/tags/HashMap实现原理/"}]},{"title":"设计模式-原型模式","slug":"设计模式-原型模式","date":"2018-06-27T08:27:11.000Z","updated":"2018-06-27T08:35:16.659Z","comments":true,"path":"2018/06/27/设计模式-原型模式/","link":"","permalink":"http://localhost:4000/2018/06/27/设计模式-原型模式/","excerpt":"","text":"1. 原型模式的定义： 原型模式：使用原型实例指定待创建对象的类型，并且通过复制这个原型来创建新的对象。 2. 原型模式的结构： 原型模式主要包含3个角色： （1）Prototype(抽象原型类)：声明克隆方法的接口，是所有具体原型类的公共父类，它可是抽象类也可以是接口，甚至可以是具体实现类。 （2）ConcretePrototype(具体原型类)：它实现抽象原型类中声明的克隆方法，在克隆方法中返回自己的一个克隆对象。 （3）Client(客户端)：在客户类中，让一个原型对象克隆自身从而创建一个新的对象。 深克隆与浅克隆： 浅克隆：当原型对象被复制时，只复制它本身和其中包含的值类型的成员变量，而引用类型的成员变量并没有复制。 深克隆：除了对象本身被复制外，对象所包含的所有成员变量也将被复制。 3. 原型模式的实现： 在使用某OA系统时，有些岗位的员工发现他们每周的工作都大同小异，因此在填写工作周报时很多内容都是重复的，为了提高工作周报的创建效率，大家迫切地希望有一种机制能够快速创建相同或者相似的周报，包括创建周报的附件。试使用原型模式对该OA系统中的工作周报创建模块进行改进。 代码如下： WeeklyLog：周报类public class WeeklyLog &#123; public Attachment Attachment &#123; get; set; &#125; public string Name &#123; get; set; &#125; public string Date &#123; get; set; &#125; public string Content &#123; get; set; &#125; /// &lt;summary&gt; /// 使用MemberwiseClone()实现浅克隆 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; //public WeeklyLog Clone() //&#123; // return (WeeklyLog)this.MemberwiseClone(); //&#125; //使用序列化的方式实现深克隆 public WeeklyLog Clone() &#123; WeeklyLog clone = null; FileStream fs = new FileStream(\"temp.dat\", FileMode.Create); BinaryFormatter formatter = new BinaryFormatter(); try &#123; formatter.Serialize(fs, this); &#125; catch (SerializationException e) &#123; Console.WriteLine(\"Failed to Serialize . Reason :\" + e.Message); throw; &#125; finally &#123; fs.Close(); &#125; FileStream fs1 = new FileStream(\"temp.dat\", FileMode.Open); BinaryFormatter formatter1 = new BinaryFormatter(); try &#123; clone = (WeeklyLog)formatter.Deserialize(fs1);//反序列化 &#125; catch (SerializationException e) &#123; Console.WriteLine(\"Failed to deserialize. Reasion:\" + e.Message); throw; &#125; finally &#123; fs1.Close(); &#125; return clone; &#125; &#125; Attachmeht:附件类public class Attachment &#123; public string Name &#123; get; set; &#125; public void Dowmload() &#123; Console.WriteLine(\"下载附件，文件名为&#123;0&#125;\", Name); &#125; &#125; 客户端代码： static void Main(string\\[\\] args)&#123; WeeklyLog log, log_new; log = new WeeklyLog(); Attachment attchment = new Attachment(); log.Attachment = attchment; log_new = log.Clone(); System.Console.WriteLine(\"周报是否相同?&#123;0&#125;\",log==log_new ? \"是\":\"否\"); System.Console.WriteLine(\"附件是否相同？&#123;0&#125;\",log.Attachment == log_new.Attachment ? \"是\":\"否\"); System.Console.ReadKey();&#125; 原型管理器： 将多个原型对象存储在一个集合中供客户端使用，它是一个专门负责克隆对象的工厂，其中定义了一个集合用于存储原型对象，如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得。 代码如下： public class PrototypeManager&#123; Hashtable ht = new Hashtable(); public PrototypeManager() &#123; ht.Add(\"A\", new ConcretePrototypeA()); ht.Add(\"B\", new ConcretePrototypeB()); &#125; public void Add(string key, Prototype prototype) &#123; ht.Add(key, prototype); &#125; public Prototype Get(string key) &#123; Prototype clone = null; clone = ((Prototype)ht\\[key\\]).Clone(); return clone; &#125;&#125; public abstract class Prototype&#123; public abstract Prototype Clone();&#125; public class ConcretePrototypeA : Prototype&#123; public override Prototype Clone() &#123; return (ConcretePrototypeA)this.MemberwiseClone(); &#125;&#125; public class ConcretePrototypeB : Prototype&#123; public override Prototype Clone() &#123; return (ConcretePrototypeB)this.MemberwiseClone(); &#125;&#125; 在实际开发当中，可以将PrototypeManager设计为单例模式，确保系统中有且只有一个PrototypeManager对象，有利于节省系统资源，还可以更好的对原型管理器对象进行控制。。。。 4. 原型模式的优缺点： 优点：（1）：当创建对象的实例较为复杂的时候，使用原型模式可以简化对象的创建过程，通过复制一个已有的实例可以提高实例的创建效率。 （2）：扩展性好，由于原型模式提供了抽象原型类，在客户端针对抽象原型类进行编程，而将具体原型类写到配置文件中，增减或减少产品对原有系统都没有影响。 （3）：原型模式提供了简化的创建结构，工厂方法模式常常需要有一个与产品类等级结构相同的工厂等级结构，而原型模式不需要这样，圆形模式中产品的复制是通过封装在类中的克隆方法实现的，无需专门的工厂类来创建产品。 （4）：可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份并将其状态保存起来，以便在需要的时候使用(例如恢复到历史某一状态)，可辅助实现撤销操作。 缺点：（1）：需要为每一个类配置一个克隆方法，而且该克隆方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违反了开闭原则。 （2）：在实现深克隆时需要编写较为复杂的代码，而且当对象之间存在多重签到引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。 5. 原型模式的适用环境： 1：创建新对象成本较大（例如初始化时间长，占用CPU多或占太多网络资源），新对象可以通过复制已有对象来获得，如果相似对象，则可以对其成员变量稍作修改。 2：系统要保存对象的状态，而对象的状态很小。 3：需要避免使用分层次的工厂类来创建分层次的对象，并且类的实例对象只有一个或很少的组合状态，通过复制原型对象得到新实例可以比使用构造函数创建一个新实例更加方便。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://localhost:4000/tags/设计模式/"},{"name":"原型模式","slug":"原型模式","permalink":"http://localhost:4000/tags/原型模式/"}]},{"title":"设计模式-建造者模式","slug":"设计模式-建造者模式","date":"2018-06-25T05:50:05.000Z","updated":"2018-06-25T06:14:46.606Z","comments":true,"path":"2018/06/25/设计模式-建造者模式/","link":"","permalink":"http://localhost:4000/2018/06/25/设计模式-建造者模式/","excerpt":"","text":"建造者模式（builder），将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 简介建造者模式（builder）是创建一个复杂对象的创建型模式，将构建复杂对象的过程和它的部件解耦，使得构建过程和部件的表示分离开来。例如我们要DIY一个台式机电脑，我们找到DIY商家，我们可以要求这台电脑的cpu或者主板或者其他的部件都是什么牌子的什么配置的，这些部件是我们可以根据我们的需求来变化的，但是这些部件组装成电脑的过程是一样的，我们不需要知道这些部件是怎样组装成电脑的，我们只需要提供部件的牌子和配置就可以了。对于这种情况我们就可以采用建造者模式，将部件和组装过程分离，使得构建过程和部件都可以自由拓展，两者之间的耦合也降到最低。 结构图 Dirextor: 指挥者类，用于统一组装流程 Builder：抽象Builder类，规范产品的组建，一般是由子类实现。 ConcreteBulider: 抽象Builder类的实现类，实现抽象Builder类定义的所有方法，并且返回一个组建好的对象 Product: 产品类 简单实现1. 创建产品类我要组装一台电脑，电脑被抽象为Computer类，它有三个部件:CPU 、主板和内存。并在里面提供了三个方法分别用来设置CPU 、主板和内存：public class Computer &#123; private String mCpu; private String mMainboard; private String mRam; public void setmCpu(String mCpu) &#123; this.mCpu = mCpu; &#125; public void setmMainboard(String mMainboard) &#123; this.mMainboard = mMainboard; &#125; public void setmRam(String mRam) &#123; this.mRam = mRam; &#125;&#125; 2.创建Builder类规范产品的组建商家组装电脑有一套组装方法的模版，就是一个抽象的Builder类,里面提供了安装CPU、主板和内存的方法，以及组装成电脑的create方法：public abstract class Builder &#123; public abstract void buildCpu(String cpu); public abstract void buildMainboard(String mainboard); public abstract void buildRam(String ram); public abstract Computer create();&#125; 商家实现了抽象的Builder类，MoonComputerBuilder类用于组装电脑：public class MoonComputerBuilder extends Builder &#123; private Computer mComputer = new Computer(); @Override public void buildCpu(String cpu) &#123; mComputer.setmCpu(cpu); &#125; @Override public void buildMainboard(String mainboard) &#123; mComputer.setmMainboard(mainboard); &#125; @Override public void buildRam(String ram) &#123; mComputer.setmRam(ram); &#125; @Override public Computer create() &#123; return mComputer; &#125;&#125; 3. 用Dirextor指挥者类来统一组装过程商家的指挥者类用来规范组装电脑的流程规范，先安装主板，再安装CPU，最后安装内存并组装成电脑：public class Direcror &#123; Builder mBuild=null; public Direcror(Builder build)&#123; this.mBuild=build; &#125; public Computer CreateComputer(String cpu,String mainboard,String ram)&#123; //规范建造流程 this.mBuild.buildMainboard(mainboard); this.mBuild.buildCpu(cpu); this.mBuild.buildRam(ram); return mBuild.create(); &#125;&#125; 4. 客户端调用指挥者类最后商家用指挥者类组装电脑。我们只需要提供我们想要的CPU，主板和内存就可以了，至于商家怎样组装的电脑我们无需知道。 public class CreatComputer { public static void main(String[]args){ Builder mBuilder=new MoonComputerBuilder(); Direcror mDirecror=new Direcror(mBuilder); //组装电脑 mDirecror.CreateComputer(\"i7-6700\",\"华擎玩家至尊\",\"三星DDR4\"); } } 使用建造者模式的场景和优缺点1. 使用场景 当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式时。相同的方法，不同的执行顺序，产生不同的事件结果时。 多个部件或零件,都可以装配到一个对象中，但是产生的运行结果又不相同时。 产品类非常复杂，或者产品类中的调用顺序不同产生了不同的效能。 创建一些复杂的对象时，这些对象的内部组成构件间的建造顺序是稳定的，但是对象的内部组成构件面临着复杂的变化 2. 优点 使用建造者模式可以使客户端不必知道产品内部组成的细节。 具体的建造者类之间是相互独立的，容易扩展。 由于具体的建造者是独立的，因此可以对建造过程逐步细化，而不对其他的模块产生任何影响。 3. 缺点 产生多余的Build对象以及Dirextor类。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://localhost:4000/tags/设计模式/"},{"name":"建造者模式","slug":"建造者模式","permalink":"http://localhost:4000/tags/建造者模式/"}]},{"title":"JVM类加载机制","slug":"JVM类加载机制","date":"2018-06-22T06:02:56.000Z","updated":"2018-06-22T06:06:03.332Z","comments":true,"path":"2018/06/22/JVM类加载机制/","link":"","permalink":"http://localhost:4000/2018/06/22/JVM类加载机制/","excerpt":"","text":"原文出处： ziwenxie 如下图所示，JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。 加载加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。 验证这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。 准备准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为： public static int v = 8080; 实际上变量v在准备阶段过后的初始值为0而不是8080，将v赋值为8080的putstatic指令是程序被编译后，存放于类构造器方法之中，这里我们后面会解释。但是注意如果声明为： public static final int v = 8080; 在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v赋值为8080。 解析解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中的： CONSTANT_Class_info CONSTANT_Field_info CONSTANT_Method_info 等类型的常量。 下面我们解释一下符号引用和直接引用的概念： 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 初始化初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。 初始化阶段是执行类构造器方法的过程。方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证方法执行之前，父类的方法已经执行完毕。p.s: 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成()方法。 注意以下几种情况不会执行类初始化： 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 定义对象数组，不会触发该类的初始化。 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。 通过类名获取Class对象，不会触发类的初始化。 通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 通过ClassLoader默认的loadClass方法，也不会触发初始化动作。 类加载器虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提供了3种类加载器： 启动类加载器(Bootstrap ClassLoader)：负责加载 JAVA_HOME\\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader实现自定义的类加载器。 当一个类加载器收到类加载任务，会先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。 采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象。 在有些情境中可能会出现要我们自己来实现一个类加载器的需求，由于这里涉及的内容比较广泛，我想以后单独写一篇文章来讲述，不过这里我们还是稍微来看一下。我们直接看一下jdk中的ClassLoader的源码实现：protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // If still not found, then invoke findClass in order // to find the class. c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c;&#125; 首先通过Class c = findLoadedClass(name);判断一个类是否已经被加载过。 如果没有被加载过执行if (c == null)中的程序，遵循双亲委派的模型，首先会通过递归从父加载器开始找，直到父类加载器是Bootstrap ClassLoader为止。 最后根据resolve的值，判断这个class是否需要解析。 而上面的findClass()的实现如下，直接抛出一个异常，并且方法是protected，很明显这是留给我们开发者自己去实现的，这里我们以后我们单独写一篇文章来讲一下如何重写findClass方法来实现我们自己的类加载器。 protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { throw new ClassNotFoundException(name); } ReferencesUNDERSTANDING THE JVM","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://localhost:4000/tags/JVM/"},{"name":"类加载机制","slug":"类加载机制","permalink":"http://localhost:4000/tags/类加载机制/"}]},{"title":"设计模式-单例模式","slug":"设计模式-单例模式","date":"2018-06-21T10:06:39.000Z","updated":"2018-06-22T06:25:13.460Z","comments":true,"path":"2018/06/21/设计模式-单例模式/","link":"","permalink":"http://localhost:4000/2018/06/21/设计模式-单例模式/","excerpt":"","text":"单例模式是设计模式中最简单的形式之一。这一模式的目的是使得类的一个对象成为系统中的唯一实例。要实现这一点，可以从客户端对其进行实例化开始。因此需要用一种只允许生成对象类的唯一实例的机制，“阻止”所有想要生成对象的访问。使用工厂方法来限制实例化过程。这个方法应该是静态方法（类方法），因为让类的实例去生成另一个唯一实例毫无意义。 一、特点 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 二、懒汉模式懒汉式单例模式：在类加载时不初始化。 1. 懒汉，线程不安全public class SingletonDemo1 &#123; private static SingletonDemo1 instance; private SingletonDemo1()&#123;&#125; public static SingletonDemo1 getInstance()&#123; if (instance == null) &#123; instance = new SingletonDemo1(); &#125; return instance; &#125;&#125; 这种写法lazy loading很明显，但是致命的是在多线程不能正常工作。 2. 懒汉，线程安全public class SingletonDemo2 &#123; private static SingletonDemo2 instance; private SingletonDemo2()&#123;&#125; public static synchronized SingletonDemo2 getInstance()&#123; if (instance == null) &#123; instance = new SingletonDemo2(); &#125; return instance; &#125;&#125; 这种写法在getInstance()方法中加入了synchronized锁。能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是效率很低（因为锁），并且大多数情况下不需要同步。 3. 双重校验锁public class SingletonDemo7 &#123; private volatile static SingletonDemo7 singletonDemo7; private SingletonDemo7()&#123;&#125; public static SingletonDemo7 getSingletonDemo7()&#123; if (singletonDemo7 == null) &#123; synchronized (SingletonDemo7.class) &#123; if (singletonDemo7 == null) &#123; singletonDemo7 = new SingletonDemo7(); &#125; &#125; &#125; return singletonDemo7; &#125;&#125; 二、饿汉模式在类加载时就完成了初始化，所以类加载比较慢，但获取对象的速度快。 1. 饿汉public class SingletonDemo3 &#123; private static SingletonDemo3 instance = new SingletonDemo3(); private SingletonDemo3()&#123;&#125; public static SingletonDemo3 getInstance()&#123; return instance; &#125;&#125; 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，这时候初始化instance显然没有达到lazy loading的效果。 2. 饿汉，变种public class SingletonDemo4 &#123; private static SingletonDemo4 instance = null; static&#123; instance = new SingletonDemo4(); &#125; private SingletonDemo4()&#123;&#125; public static SingletonDemo4 getInstance()&#123; return instance; &#125;&#125; 表面上看起来差别挺大，其实更第三种方式差不多，都是在类初始化即实例化instance 3. 静态内部类public class SingletonDemo5 &#123; private static class SingletonHolder&#123; private static final SingletonDemo5 instance = new SingletonDemo5(); &#125; private SingletonDemo5()&#123;&#125; public static final SingletonDemo5 getInsatance()&#123; return SingletonHolder.instance; &#125;&#125; 这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第1种和第2种方式不同的是（很细微的差别）：第1种和第2种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方法就显得更合理。 三、枚举public enum SingletonDemo6 &#123; instance; public void whateverMethod()&#123; &#125;&#125; 这种方式是Effective Java作者Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊，不过，个人认为由于1.5中才加入enum特性，用这种方式写不免让人感觉生疏，在实际工作中，我也很少看见有人这么写过。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://localhost:4000/tags/设计模式/"},{"name":"单例模式","slug":"单例模式","permalink":"http://localhost:4000/tags/单例模式/"}]},{"title":"JVM内存模型","slug":"JVM内存模型","date":"2018-06-20T06:45:10.000Z","updated":"2018-07-10T09:45:07.005Z","comments":true,"path":"2018/06/20/JVM内存模型/","link":"","permalink":"http://localhost:4000/2018/06/20/JVM内存模型/","excerpt":"","text":"1. 程序计数器 程序计数器是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器。 在虚拟机概念模型（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程回复等基础功能都需要依赖这个计数器来完成。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryErorr情况的区域。 2. Java虚拟机栈 线程私有，它的生命周期与线程相同 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口灯信息。 在Java虚拟机规范中，对这个区域规定了两种异常： 如果线程请求的栈的深度大于虚拟机所允许的深度，将抛出 StackOverflowError异常； 如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常 3. 本地方法栈 本地方法栈与虚拟机栈发挥的作用是非常相似的。他们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。","categories":[],"tags":[{"name":"JVM内存模型","slug":"JVM内存模型","permalink":"http://localhost:4000/tags/JVM内存模型/"}]},{"title":"UML类图与类的关系详解","slug":"UML类图与类的关系详解","date":"2018-06-20T03:34:48.000Z","updated":"2018-06-20T03:36:47.018Z","comments":true,"path":"2018/06/20/UML类图与类的关系详解/","link":"","permalink":"http://localhost:4000/2018/06/20/UML类图与类的关系详解/","excerpt":"","text":"虚线箭头指向依赖； 实线箭头指向关联； 虚线三角指向接口； 实线三角指向父类； 空心菱形能分离而独立存在，是聚合； 实心菱形精密关联不可分，是组合； 上面是UML的语法。 在画类图的时候，理清类和类之间的关系是重点。类的关系有泛化(Generalization)、实现（Realization）、依赖(Dependency)和关联(Association)。其中关联又分为一般关联关系和聚合关系(Aggregation)，合成关系(Composition)。下面我们结合实例理解这些关系。 基本概念类图（Class Diagram）: 类图是面向对象系统建模中最常用和最重要的图，是定义其它图的基础。类图主要是用来显示系统中的类、接口以及它们之间的静态结构和关系的一种静态模型。 类图的3个基本组件：类名、属性、方法。 泛化(generalization)：表示is-a的关系，是对象之间耦合度最大的一种关系，子类继承父类的所有细节。直接使用语言中的继承表达。在类图中使用带三角箭头的实线表示，箭头从子类指向父类。 实现（Realization）:在类图中就是接口和实现的关系。这个没什么好讲的。在类图中使用带三角箭头的虚线表示，箭头从实现类指向接口。 依赖(Dependency)：对象之间最弱的一种关联方式，是临时性的关联。代码中一般指由局部变量、函数参数、返回值建立的对于其他对象的调用关系。一个类调用被依赖类中的某些方法而得以完成这个类的一些职责。在类图使用带箭头的虚线表示，箭头从使用类指向被依赖的类。 关联(Association) : 对象之间一种引用关系，比如客户类与订单类之间的关系。这种关系通常使用类的属性表达。关联又分为一般关联、聚合关联与组合关联。后两种在后面分析。在类图使用带箭头的实线表示，箭头从使用类指向被关联的类。可以是单向和双向。 聚合(Aggregation) : 表示has-a的关系，是一种不稳定的包含关系。较强于一般关联,有整体与局部的关系,并且没有了整体,局部也可单独存在。如公司和员工的关系，公司包含员工，但如果公司倒闭，员工依然可以换公司。在类图使用空心的菱形表示，菱形从局部指向整体。 组合(Composition) : 表示contains-a的关系，是一种强烈的包含关系。组合类负责被组合类的生命周期。是一种更强的聚合关系。部分不能脱离整体存在。如公司和部门的关系，没有了公司，部门也不能存在了；调查问卷中问题和选项的关系；订单和订单选项的关系。在类图使用实心的菱形表示，菱形从局部指向整体。 多重性(Multiplicity) : 通常在关联、聚合、组合中使用。就是代表有多少个关联对象存在。使用数字..星号（数字）表示。如下图，一个割接通知可以关联0个到N个故障单。 聚合和组合的区别这两个比较难理解，重点说一下。聚合和组合的区别在于：聚合关系是“has-a”关系，组合关系是“contains-a”关系；聚合关系表示整体与部分的关系比较弱，而组合比较强；聚合关系中代表部分事物的对象与代表聚合事物的对象的生存期无关，一旦删除了聚合对象不一定就删除了代表部分事物的对象。组合中一旦删除了组合对象，同时也就删除了代表部分事物的对象。 实例分析联通客户响应OSS。系统有故障单、业务开通、资源核查、割接、业务重保、网络品质性能等功能模块。现在我们抽出部分需求做为例子讲解。 大家可以参照着类图，好好理解。 1． 通知分为一般通知、割接通知、重保通知。这个是继承关系。 2． NoticeService和实现类NoticeServiceImpl是实现关系。 3． NoticeServiceImpl通过save方法的参数引用Notice,是依赖关系。同时调用了BaseDao完成功能，也是依赖关系。 4． 割接通知和故障单之间通过中间类(通知电路)关联，是一般关联。 5． 重保通知和预案库间是聚合关系。因为预案库可以事先录入，和重保通知没有必然联系，可以独立存在。在系统中是手工从列表中选择。删除重保通知，不影响预案。 6． 割接通知和需求单之间是聚合关系。同理，需求单可以独立于割接通知存在。也就是说删除割接通知，不影响需求单。 7． 通知和回复是组合关系。因为回复不能独立于通知存在。也就是说删除通知，该条通知对应的回复也要级联删除。 经过以上的分析，相信大家对类的关系已经有比较好的理解了。大家有什么其它想法或好的见解，欢迎拍砖。 PS：还是那句话：以上类图用Enterprise Architect 7.5所画，在此推荐一下EA,非常不错。可以替代Visio和Rose了。Visio功能不够强大，Rose太重。唯有EA比较合适。 本文完全转载自http://www.uml.org.cn/oobject/201104212.asp","categories":[],"tags":[{"name":"类图","slug":"类图","permalink":"http://localhost:4000/tags/类图/"},{"name":"UML","slug":"UML","permalink":"http://localhost:4000/tags/UML/"}]},{"title":"设计模式-工厂模式","slug":"设计模式-工厂模式","date":"2018-06-19T12:50:21.000Z","updated":"2018-06-25T05:28:14.850Z","comments":true,"path":"2018/06/19/设计模式-工厂模式/","link":"","permalink":"http://localhost:4000/2018/06/19/设计模式-工厂模式/","excerpt":"","text":"首先，简单工厂模式不属于23中涉及模式，简单工厂一般分为：普通简单工厂、多方法简单工厂、静态方法简单工厂。 一、简单工厂模式简单工厂模式模式分为三种： 1. 普通就是建立一个工厂类，对实现了同一接口的一些类进行实例的创建。首先看下关系图： 举例如下：（我们举一个发送邮件和短信的例子）首先，创建二者的共同接口：public interface Sender &#123; public void Send(); &#125; 其次，创建实现类：public class MailSender implements Sender &#123; @Override public void Send() &#123; System.out.println(\"this is mailsender!\"); &#125; &#125; public class SmsSender implements Sender &#123; @Override public void Send() &#123; System.out.println(\"this is sms sender!\"); &#125; &#125; 最后，建工厂类：public class SendFactory &#123; public Sender produce(String type) &#123; if (\"mail\".equals(type)) &#123; return new MailSender(); &#125; else if (\"sms\".equals(type)) &#123; return new SmsSender(); &#125; else &#123; System.out.println(\"请输入正确的类型!\"); return null; &#125; &#125; &#125; ``` 我们来测试下：``` javapublic class FactoryTest &#123; public static void main(String[] args) &#123; SendFactory factory = new SendFactory(); Sender sender = factory.produce(\"sms\"); sender.Send(); &#125; &#125; 输出：this is sms sender! 2. 多个方法是对普通工厂方法模式的改进，在普通工厂方法模式中，如果传递的字符串出错，则不能正确创建对象，而多个工厂方法模式是提供多个工厂方法，分别创建对象。关系图：将上面的代码做下修改，改动下SendFactory类就行，如下：public class SendFactory &#123; public Sender produceMail()&#123; return new MailSender(); &#125; public Sender produceSms()&#123; return new SmsSender(); &#125; &#125; 测试类如下：public class FactoryTest &#123; public static void main(String[] args) &#123; SendFactory factory = new SendFactory(); Sender sender = factory.produceMail(); sender.Send(); &#125; &#125; 3. 多个静态方法将上面的多个工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。 public class SendFactory &#123; public static Sender produceMail()&#123; return new MailSender(); &#125; public static Sender produceSms()&#123; return new SmsSender(); &#125; &#125; 测试类如下：public class FactoryTest &#123; public static void main(String[] args) &#123; Sender sender = SendFactory.produceMail(); sender.Send(); &#125; &#125; 总体来说，工厂模式适合：凡是出现了大量的产品需要创建，并且具有共同的接口时，可以通过工厂方法模式进行创建。在以上的三种模式中，第一种如果传入的字符串有误，不能正确创建对象，第三种相对于第二种，不需要实例化工厂类，所以，大多数情况下，我们会选用第三种——静态工厂方法模式。 二、工厂方法模式（Factory Method）简单工厂模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到工厂方法模式，创建一个工厂接口和创建多个工厂实现类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。 请看例子：接口public interface Sender &#123; public void Send(); &#125; 两个实现类public class MailSender implements Sender &#123; @Override public void Send() &#123; System.out.println(\"this is mailsender!\"); &#125; &#125; public class SmsSender implements Sender &#123; @Override public void Send() &#123; System.out.println(\"this is sms sender!\"); &#125; &#125; 两个工厂类：public class SendMailFactory implements Provider &#123; @Override public Sender produce()&#123; return new MailSender(); &#125; &#125; public class SendSmsFactory implements Provider&#123; @Override public Sender produce() &#123; return new SmsSender(); &#125; &#125; 在提供一个接口：public interface Provider &#123; public Sender produce(); &#125; 测试类：public class Test &#123; public static void main(String[] args) &#123; Provider provider = new SendMailFactory(); Sender sender = provider.produce(); sender.Send(); &#125; &#125; 其实这个模式的好处就是，如果你现在想增加一个功能：发及时信息，则只需做一个实现类，实现Sender接口，同时做一个工厂类，实现Provider接口，就OK了，无需去改动现成的代码。这样做，拓展性较好！ 三、抽象工厂模式工厂方法模式和抽象工厂模式区别如下： 工厂方法模式：一个抽象产品类，可以派生出多个具体产品类。一个抽象工厂类，可以派生出多个具体工厂类。每个具体工厂类只能创建一个具体产品类的实例。 抽象工厂模式：多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。一个抽象工厂类，可以派生出多个具体工厂类。每个具体工厂类可以创建多个具体产品类的实例，也就是创建的是一个产品线下的多个产品。 区别：工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个。工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个。工厂方法创建 “一种” 产品，他的着重点在于”怎么创建”，也就是说如果你开发，你的大量代码很可能围绕着这种产品的构造，初始化这些细节上面。也因为如此，类似的产品之间有很多可以复用的特征，所以会和模版方法相随。 抽象工厂需要创建一些列产品，着重点在于”创建哪些”产品上，也就是说，如果你开发，你的主要任务是划分不同差异的产品线，并且尽量保持每条产品线接口一致，从而可以从同一个抽象工厂继承。 来看看抽象工厂模式的各个角色（和工厂方法的如出一辙）：抽象工厂角色： 这是工厂方法模式的核心，它与应用程序无关。是具体工厂角色必须实现的接口或者必须继承的父类。在java中它由抽象类或者接口来实现。具体工厂角色：它含有和具体业务逻辑有关的代码。由应用程序调用以创建对应的具体产品的对象。在java中它由具体的类来实现。抽象产品角色：它是具体产品继承的父类或者是实现的接口。在java中一般有抽象类或者接口来实现。具体产品角色：具体工厂角色所创建的对象就是此角色的实例。在java中由具体的类来实现。/抽象产品（Bmw和Audi同理） abstract class BenzCar&#123; private String name; public abstract void drive(); public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; //具体产品（Bmw和Audi同理） class BenzSportCar extends BenzCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----BenzSportCar-----------------------\"); &#125; &#125; class BenzBusinessCar extends BenzCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----BenzBusinessCar-----------------------\"); &#125; &#125; abstract class BmwCar&#123; private String name; public abstract void drive(); public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; class BmwSportCar extends BmwCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----BmwSportCar-----------------------\"); &#125; &#125; class BmwBusinessCar extends BmwCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----BmwBusinessCar-----------------------\"); &#125; &#125; abstract class AudiCar&#123; private String name; public abstract void drive(); public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; class AudiSportCar extends AudiCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----AudiSportCar-----------------------\"); &#125; &#125; class AudiBusinessCar extends AudiCar&#123; public void drive()&#123; System.out.println(this.getName()+\"----AudiBusinessCar-----------------------\"); &#125; &#125; //抽象工厂 abstract class Driver3&#123; public abstract BenzCar createBenzCar(String car) throws Exception; public abstract BmwCar createBmwCar(String car) throws Exception; public abstract AudiCar createAudiCar(String car) throws Exception; &#125; //具体工厂 class SportDriver extends Driver3&#123; public BenzCar createBenzCar(String car) throws Exception &#123; return new BenzSportCar(); &#125; public BmwCar createBmwCar(String car) throws Exception &#123; return new BmwSportCar(); &#125; public AudiCar createAudiCar(String car) throws Exception &#123; return new AudiSportCar(); &#125; &#125; class BusinessDriver extends Driver3&#123; public BenzCar createBenzCar(String car) throws Exception &#123; return new BenzBusinessCar(); &#125; public BmwCar createBmwCar(String car) throws Exception &#123; return new BmwBusinessCar(); &#125; public AudiCar createAudiCar(String car) throws Exception &#123; return new AudiBusinessCar(); &#125; &#125; //老板 public class BossAbstractFactory &#123; public static void main(String[] args) throws Exception &#123; Driver3 d = new BusinessDriver(); AudiCar car = d.createAudiCar(\"\"); car.drive(); &#125; &#125; 所以抽象工厂模式一般用于具有产品树和产品族的场景下。抽象工厂模式的缺点：如果需要增加新的产品树，那么就要新增三个产品类，比如VolvoCar，VolvoSportCar,VolvoSportCar，并且要修改三个工厂类。这样大批量的改动是很丑陋的做法。所以可以用简单工厂配合反射来改进抽象工厂：UML图略。 abstract class BenzCar{ private String name; public abstract void drive(); public String getName() { return name; } public void setName(String name) { this.name = name; } } class BenzSportCar extends BenzCar{ public void drive(){ System.out.println(this.getName()+\"----BenzSportCar-----------------------\"); } } class BenzBusinessCar extends BenzCar{ public void drive(){ System.out.println(this.getName()+\"----BenzBusinessCar-----------------------\"); } } abstract class BmwCar{ private String name; public abstract void drive(); public String getName() { return name; } public void setName(String name) { this.name = name; } } class BmwSportCar extends BmwCar{ public void drive(){ System.out.println(this.getName()+\"----BmwSportCar-----------------------\"); } } class BmwBusinessCar extends BmwCar{ public void drive(){ System.out.println(this.getName()+\"----BmwBusinessCar-----------------------\"); } } abstract class AudiCar{ private String name; public abstract void drive(); public String getName() { return name; } public void setName(String name) { this.name = name; } } class AudiSportCar extends AudiCar{ public void drive(){ System.out.println(this.getName()+\"----AudiSportCar-----------------------\"); } } class AudiBusinessCar extends AudiCar{ public void drive(){ System.out.println(this.getName()+\"----AudiBusinessCar-----------------------\"); } } /** * 简单工厂通过反射改进抽象工厂及其子工厂 * @author Administrator * */ class Driver3{ public static BenzCar createBenzCar(String car) throws Exception { return (BenzCar) Class.forName(car).newInstance(); } public static BmwCar createBmwCar(String car) throws Exception { return (BmwCar) Class.forName(car).newInstance(); } public static AudiCar createAudiCar(String car) throws Exception { return (AudiCar) Class.forName(car).newInstance(); } } //客户端 public class SimpleAndAbstractFactory { public static void main(String[] args) throws Exception { AudiCar car = Driver3.createAudiCar(\"com.java.pattendesign.factory.AudiSportCar\"); car.drive(); } }","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://localhost:4000/tags/设计模式/"},{"name":"工厂模式","slug":"工厂模式","permalink":"http://localhost:4000/tags/工厂模式/"}]},{"title":"GoLang","slug":"GoLang","date":"2018-06-19T09:51:02.000Z","updated":"2018-06-20T03:07:44.776Z","comments":true,"path":"2018/06/19/GoLang/","link":"","permalink":"http://localhost:4000/2018/06/19/GoLang/","excerpt":"","text":"一、下载安装下载对应操作系统的版本并安装，下载地址：http://www.golangtc.com/download， 譬如这里下载的是 go1.6beta1.windows-amd64.msi。 二、Windows下环境配置 GOROOT golang安装后的根目录，windows下默认为c:\\go\\，安装过程中会由安装程序自动写入系统环境变量中。 GOROOT: D:\\Program Files\\Go\\ GOBIN golang安装后根目录下的bin目录，即$GOROOT\\bin\\，windows平台下默认为c:\\go\\bin，安装过程中会由安装程序自动添加到PATH环境变量中。 GOBIN: %GOROOT%\\bin GOPATH golang的工作目录，是用来设置包加载路径的重要变量，也是go get和go install工具将会使用的目录。GOPATH变量可以同时制定多个目录，这些目录在Mac和Linux系统上通过:分隔，而在windows系统上通过;分隔。在大部分情况下都将是第一个路径优先。 GOPATH: D:\\golang\\workspace\\ 打开cmd，运行go version命令，如果看到下面信息说明环境变量配置成功。 C:\\Users\\Administrator&gt;go versiongo version go1.9.2 windows/amd64 三、LiteIDE安装 下载windows版本，下载地址：http://www.golangtc.com/download/liteide。 将liteidex28.windows-qt4.zip解压到本地即可，例如：c:\\liteide\\。 检查LiteIDE环境变量：工具栏选择切换当前环境win64,让后 查看 =&gt; 编辑当前环境 # native compiler windows amd64GOROOT=D:\\Program Files\\Go#GOBIN=GOARCH=amd64GOOS=windowsCGO_ENABLED=1PATH=D:\\golang\\mingw64\\bin;%GOROOT%\\bin;%PATH%LITEIDE_GDB=gdb64LITEIDE_MAKE=mingw32-makeLITEIDE_TERM=%COMSPEC%LITEIDE_TERMARGS=LITEIDE_EXEC=%COMSPEC%LITEIDE_EXECOPT=/C 四、MinGW-w64 GCC toolchains安装在LiteIDE上调试golang需要安装gdb，windows上则可使用MinGW-w64。LiteIDE的环境变量LITEIDE_GDB可以指定使用哪一个gdb来执行调试：在windows上，32位环境使用gdb.exe，64位环境使用gdb64.exe。在环境配置文件中可对这个环境变量进行手工配置。 下载MinGW GCC toolchains，下载地址：http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/rubenvb/gcc-4.8-release/ 将x86_64-w64-mingw32-gcc-4.8.0-win64_rubenvb.7z解压到本地即可，例如：D:\\golang\\mingw64\\。 检查修改LiteIDE环境变量：查看(V) =&gt; 编辑当前环境# native compiler windows amd64GOROOT=D:\\Program Files\\Go#GOBIN=GOARCH=amd64GOOS=windowsCGO_ENABLED=1PATH=D:\\golang\\mingw64\\bin;%GOROOT%\\bin;%PATH%LITEIDE_GDB=gdb64LITEIDE_MAKE=mingw32-makeLITEIDE_TERM=%COMSPEC%LITEIDE_TERMARGS=LITEIDE_EXEC=%COMSPEC%LITEIDE_EXECOPT=/C 五、GOPATH 设置查看 → 管理 GOPATH…，我们这里就使用安装 Go 时设置的那个 GOPATH 六、新建项目Ctrl + N 打开新项目或文件对话框，GOPATH 选择上一步的那个，模板选择 Go1 Command Project，最后取个名字，比如 test：点击 OK，test 项目已建立：完整测试代码：// test project main.gopackage mainimport ( \"fmt\")func main() &#123; var i int = 20 i += 30 j := i + 10 fmt.Println(j)&#125; 七、设置编译选项并编译编译 → 编译配置，BUILDARGS 设置为 -gcflags “-N -l”，以去掉编译优化，方便调试： 八、项目调试按 F5 启动调试，程序在 main 函数处停止：按 F10 （逐过程）进行单步调试，注意变量 i、j 值的变化：按 F11 （逐语句） 参考文章golang环境搭建Windows 平台下 LiteIDE 的安装和使用","categories":[],"tags":[{"name":"GoLang","slug":"GoLang","permalink":"http://localhost:4000/tags/GoLang/"},{"name":"环境配置","slug":"环境配置","permalink":"http://localhost:4000/tags/环境配置/"}]},{"title":"设计模式","slug":"设计模式","date":"2018-06-19T05:21:04.000Z","updated":"2018-06-19T09:51:15.977Z","comments":true,"path":"2018/06/19/设计模式/","link":"","permalink":"http://localhost:4000/2018/06/19/设计模式/","excerpt":"","text":"一 设计模式分类 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 其实还有两类：并发型模式和线程池模式。 二 设计模式的六大原则总原则：开闭原则（Open Close Principle）开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，而是要扩展原有代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类等，后面的具体设计中我们会提到这点。 1. 单一职责原则不要存在多于一个导致类变更的原因，也就是说每个类应该实现单一的职责，如若不然，就应该吧类拆分。 2. 里氏替换原则（Liskov Subsitution Principle） 里氏替换原则（Liskov Subsitution Principle LSP）面向对象设计的基本原则之一。里氏替换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时。基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏替换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏替换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科 里氏替换原则中，子类对父类的方法尽量不要重写和重载。因为父类代表了定义好的结构，通过这个规范的接口与外界交互，子类不应该随便破坏它。 3. 依赖倒转原则（Dependence Inversion Principle） 这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。写代码时用到的具体类时，不与具体类交互，而与具体类的上层接口交互。 4. 接口隔离原则（Interface Segregation Principle） 这个原则的意思是：每个接口中不存在子类用不到却必须实现的方法，如果不然，就要将接口拆分。使用多个隔离的接口，比使用单个接口（多个接口方法集合到一个的接口）要好。 5. 迪米特法则（最少知道原则）（Demeter Principle） 就是说：一个类对自己依赖的类知道的越少越好。也就是说无论被依赖的类多么复杂，都应该将逻辑封装在方法的内部，通过public方法提供给外部。这样当被依赖的类变化时，才能最小的影响该类。 最少知道原则的另一个表达方式是：只与直接的朋友通信。类之间只要有耦合关系，就叫朋友关系。耦合分为依赖、关联、聚合、组合等。我们称出现为成员变量、方法参数、方法返回值中的类为直接朋友。局部变量、临时变量则不是直接的朋友。我们要求陌生的类不要作为局部变量出现在类中。 6. 合成复用原则（Composite Reuse Principle） 原则是尽量首先使用合成/聚合的方式，而不是使用继承。","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://localhost:4000/tags/设计模式/"}]},{"title":"Spring boot 系列（四）filter shiro","slug":"Spring boot 系列（四）","date":"2018-06-07T02:48:15.000Z","updated":"2018-06-19T02:48:33.679Z","comments":true,"path":"2018/06/07/Spring boot 系列（四）/","link":"","permalink":"http://localhost:4000/2018/06/07/Spring boot 系列（四）/","excerpt":"","text":"","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://localhost:4000/tags/spring-boot/"},{"name":"filter","slug":"filter","permalink":"http://localhost:4000/tags/filter/"},{"name":"shiro","slug":"shiro","permalink":"http://localhost:4000/tags/shiro/"}]},{"title":"Spring boot 系列（三）tomcat部署","slug":"Spring boot 系列（三）","date":"2018-06-06T03:04:36.000Z","updated":"2018-06-19T02:48:06.402Z","comments":true,"path":"2018/06/06/Spring boot 系列（三）/","link":"","permalink":"http://localhost:4000/2018/06/06/Spring boot 系列（三）/","excerpt":"","text":"1. 修改打包方式 在pom.xml里设置 war 2. 移除嵌入式tomcat插件 在pom.xml里找到spring-boot-starter-web依赖节点，在其中添加如下代码 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 移除嵌入式tomcat插件 --&gt; &lt;!-- &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; --&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 3. 添加servlet-api的依赖&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 4. 修改启动类，继承 SpringBootServletInitializer 并重写 configure 方法 /** * SprintBootApplication */@SpringBootApplicationpublic class BootApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; // 注意这里要指向原先用main方法执行的Application启动类 return application.sources(BootApplication.class); &#125; /** * @param args */ public static void main(String[] args) &#123; SpringApplication.run(BootApplication.class, args); &#125;&#125; 5. maven 打包 mvn clean compile package","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://localhost:4000/tags/spring-boot/"},{"name":"tomcat部署","slug":"tomcat部署","permalink":"http://localhost:4000/tags/tomcat部署/"}]},{"title":"Spring boot 系列（二）文件上传","slug":"Spring boot 系列（二）","date":"2018-06-06T02:24:45.000Z","updated":"2018-06-19T02:48:19.909Z","comments":true,"path":"2018/06/06/Spring boot 系列（二）/","link":"","permalink":"http://localhost:4000/2018/06/06/Spring boot 系列（二）/","excerpt":"","text":"实现功能说明文件上传，并支持展示上传文件 问题描述 报错信息 org.springframework.web.multipart.MultipartException: Could not parse multipart servlet request; nested exception is java.io.IOException: The temporary upload location [/tmp/tomcat.2737591724424319502.8080/work/Tomcat/localhost/ROOT] is not valid 报错代码 : file.transferTo 方法 public String storeScale(MultipartFile file, String basePath, int maxWidth) throws Exception &#123; validateFile(file); String root = getRoot(); String path = FileNameUtils.genPathAndFileName(getExt(file.getOriginalFilename())); File temp = new File(root + appContext.getTempDir() + path); checkDirAndCreate(temp); try &#123; file.transferTo(temp); // 根据临时文件生成略缩图 String dest = root + basePath + path; ImageUtils.scaleImageByWidth(temp.getAbsolutePath(), dest, maxWidth); &#125; catch (Exception e) &#123; throw e; &#125; finally &#123; temp.delete(); &#125; return basePath + path;&#125; 问题分析 上面源码文件使用路径 ，相对路径, 预期路径应该是 root + appContext.getTempDir() + path ，但是报错却是一个系统临时文件路径 （Tomcat的） 其次，由于transferTo方法报错，应该是写文件的时候报错，跟踪源码如下 /** * Spring MultipartHttpServletRequest adapter, wrapping a Servlet 3.0 HttpServletRequest * and its Part objects. Parameters get exposed through the native request's getParameter * methods - without any custom processing on our side. * * @author Juergen Hoeller * @author Rossen Stoyanchev * @since 3.1 */public class StandardMultipartHttpServletRequest extends AbstractMultipartHttpServletRequest &#123; ... @Override public void transferTo(File dest) throws IOException, IllegalStateException &#123; this.part.write(dest.getPath()); // 写文件方法入口 if (dest.isAbsolute() &amp;&amp; !dest.exists()) &#123; // Servlet 3.0 Part.write is not guaranteed to support absolute file paths: // may translate the given path to a relative location within a temp dir // (e.g. on Jetty whereas Tomcat and Undertow detect absolute paths). // At least we offloaded the file from memory storage; it'll get deleted // from the temp dir eventually in any case. And for our user's purposes, // we can manually copy it to the requested location as a fallback. FileCopyUtils.copy(this.part.getInputStream(), new FileOutputStream(dest)); &#125; &#125; ...&#125;/** * Adaptor to allow &#123;@link FileItem&#125; objects generated by the package renamed * commons-upload to be used by the Servlet 3.0 upload API that expects * &#123;@link Part&#125;s. */public class ApplicationPart implements Part &#123; ... @Override public void write(String fileName) throws IOException &#123; File file = new File(fileName); if (!file.isAbsolute()) &#123; // 此处判断如果不是绝对路径，则会添加location file = new File(location, fileName); &#125; try &#123; fileItem.write(file); &#125; catch (Exception e) &#123; throw new IOException(e); &#125; &#125; ...&#125; 源码一目了然，使用Servlet3.0的支持的上传文件功能时，如果我们没有使用绝对路径的话，transferTo方法会在相对路径前添加一个location路径，即：file = new File(location, fileName);。当然，这也影响了SpringMVC的Multipartfile的使用 解决方法 使用绝对路径 指定临时文件location路径 /** * 文件上传临时路径 */ @Bean MultipartConfigElement multipartConfigElement() &#123; MultipartConfigFactory factory = new MultipartConfigFactory(); String location = appContext.getRoot(); File file = new File(location); if (!file.exists()) &#123; file.mkdirs();&#125; factory.setLocation(location); return factory.createMultipartConfig(); &#125; /** * appContext.getRoot() 文件存放路径 */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(\"/store/**\").addResourceLocations(\"file:\" + appContext.getRoot() + \"/store/\"); super.addResourceHandlers(registry); &#125; 文章参考：https://blog.csdn.net/daniel7443/article/details/51620308","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://localhost:4000/tags/spring-boot/"},{"name":"文件上传","slug":"文件上传","permalink":"http://localhost:4000/tags/文件上传/"}]},{"title":"org.apache.maven.archiver.MavenArchiver.getManifest错误","slug":"eclipse-maven","date":"2018-05-30T03:36:53.000Z","updated":"2018-05-30T03:45:14.979Z","comments":true,"path":"2018/05/30/eclipse-maven/","link":"","permalink":"http://localhost:4000/2018/05/30/eclipse-maven/","excerpt":"","text":"在给eclipse换了高版本的maven插件后，引入jar包报如下的错误：org.apache.maven.archiver.MavenArchiver.getManifest(org.apache.maven.project 解决方法是：help–&gt;install new software, 然后add，添加如下链接， http://repo1.maven.org/maven2/.m2e/connectors/m2eclipse-mavenarchiver/0.17.2/N/LATEST/ 一直下一步就可以，后面提示重启eclipse，然后重启eclipse后，右击项目，点击maven–&gt;update project， 错误就没了","categories":[],"tags":[{"name":"eclipse","slug":"eclipse","permalink":"http://localhost:4000/tags/eclipse/"},{"name":"maven","slug":"maven","permalink":"http://localhost:4000/tags/maven/"}]},{"title":"Spring boot 系列（一）相关文档","slug":"Spring boot 系列（一）","date":"2018-05-30T03:17:11.000Z","updated":"2018-06-19T02:48:15.681Z","comments":true,"path":"2018/05/30/Spring boot 系列（一）/","link":"","permalink":"http://localhost:4000/2018/05/30/Spring boot 系列（一）/","excerpt":"","text":"Spring官方网站本身使用Spring框架开发，随着功能以及业务逻辑的日益复杂，应用伴随着大量的XML配置文件以及复杂的Bean依赖关系。随着Spring 3.0的发布，Spring IO团队逐渐开始摆脱XML配置文件，并且在开发过程中大量使用“约定优先配置”（convention over configuration）的思想来摆脱Spring框架中各类繁复纷杂的配置（即时是Java Config）。 Spring Boot正是在这样的一个背景下被抽象出来的开发框架，它本身并不提供Spring框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于Spring框架的应用程序。也就是说，它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置（例如Jackson, JDBC, Mongo, Redis, Mail等等），Spring Boot应用中这些第三方库几乎可以零配置的开箱即用（out-of-the-box），大部分的Spring Boot应用都只需要非常少量的配置代码，开发者能够更加专注于业务逻辑。 相关文档 Spring 中文文档 http://spring.cndocs.ml/ Spring boot 中文文档 http://blog.geekidentity.com/spring/spring_boot_translation/ spring boot 2.0 官方文档 https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/ Spring Boot教程 https://www.yiibai.com/spring-boot/ spring boot 实践学习案例 https://github.com/JeffLi1993/springboot-learning-example","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://localhost:4000/tags/spring-boot/"}]},{"title":"微信公共账号（一）","slug":"微信公共账号（一）","date":"2018-05-26T01:50:04.000Z","updated":"2018-06-04T00:51:37.373Z","comments":true,"path":"2018/05/26/微信公共账号（一）/","link":"","permalink":"http://localhost:4000/2018/05/26/微信公共账号（一）/","excerpt":"","text":"订目标，做计划，大量的行动。——陈安之言之易，行之难。——吕不韦 相关文档、工具 微信公众平台技术文档官网 微信Java开发工具包 weixin-java-tools weixin-java-tools Demo 微信服务号本地调试,参考外网访问你机器上的Demo 问题AES加密时的 java.security.InvalidKeyException: Illegal key size 异常程序代码// 设置加密模式为AES的CBC模式Cipher cipher = Cipher.getInstance(\"AES/CBC/NoPadding\");SecretKeySpec keySpec = new SecretKeySpec(aesKey, \"AES\");IvParameterSpec iv = new IvParameterSpec(aesKey, 0, 16);cipher.init(Cipher.ENCRYPT_MODE, keySpec, iv);// 加密byte[] encrypted = cipher.doFinal(unencrypted);... 当执行到cipher.init(Cipher.ENCRYPT_MODE, keySpec, iv); 时, 如果密钥大于128, 会抛出java.security.InvalidKeyException: Illegal key size 异常.因为密钥长度是受限制的, java运行时环境读到的是受限的policy文件. 文件位于${java_home}/jre/lib/security, 这种限制是因为美国对软件出口的控制. 处理办法: 在官方网站下载JCE无限制权限策略文件 JDK6的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.htmlJDK7的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce-7-download-432124.htmlJDK8的下载地址: http://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html下载后解压，可以看到local_policy.jar和US_export_policy.jar以及readme.txt如果安装了JRE，将两个jar文件放到%JRE_HOME%\\lib\\security目录下覆盖原来的文件如果安装了JDK，还要将两个jar文件也放到%JDK_HOME%\\jre\\lib\\security目录下覆盖原来文件 更多问题参考weixin-java-tools微信Java SDK开发文档","categories":[],"tags":[{"name":"spring boot","slug":"spring-boot","permalink":"http://localhost:4000/tags/spring-boot/"},{"name":"maven","slug":"maven","permalink":"http://localhost:4000/tags/maven/"},{"name":"微信公共号","slug":"微信公共号","permalink":"http://localhost:4000/tags/微信公共号/"},{"name":"java","slug":"java","permalink":"http://localhost:4000/tags/java/"}]},{"title":"外网访问你机器上的Demo","slug":"外网访问你机器上的Demo","date":"2018-05-25T03:10:11.000Z","updated":"2018-05-25T03:22:00.630Z","comments":true,"path":"2018/05/25/外网访问你机器上的Demo/","link":"","permalink":"http://localhost:4000/2018/05/25/外网访问你机器上的Demo/","excerpt":"","text":"想在外网访问你机器上的demo? 几个内网端口映射服务网站 http://wendal.cn Nutz社区提供的ngrok服务，详细访问 https://nutz.cn/yvr/t/33b68q9106imspallbj4c6aa0p http://www.mofasuidao.cn/ 拥有魔法隧道，让你穿越世界，引领「内网穿透」潮流，为世界带来美好的改变 http://natapp.cn/ http://ngrok.io == http://ngrok.com http://ngrok.2bdata.com/ http://www.ngrok.cc/ http://www.nat123.com/ ngrok使用 下载ngrok,点我 打开shell或cmd，进入ngrok目录，运行 ngrok -config ngrok.cfg -subdomain my-domain 8080 如果运行失败，请更换my-domain为其它字符串，直至连接成功； 外网访问地址：http://my-domain.tunnel.qydev.com/ （注意my-domain要跟上面的一致）；","categories":[],"tags":[{"name":"代理","slug":"代理","permalink":"http://localhost:4000/tags/代理/"}]},{"title":"计划","slug":"计划","date":"2018-05-25T01:51:48.000Z","updated":"2018-05-25T09:05:34.208Z","comments":true,"path":"2018/05/25/计划/","link":"","permalink":"http://localhost:4000/2018/05/25/计划/","excerpt":"","text":"西汉·戴圣《礼记·中庸》：“凡事豫则立，不豫则废。” 计划 个人博客 微信服务号石门蓝小球 PC站Mvp51 个人博客 Hexo博客搭建教程 Hexo手机端样式调整 Hexo支持评论功能，目前计划评论功能不使用第三方插件 石门蓝小球 微信服务号后台，支持用户上传收集信息（文字、图片、语音） 支持查询石家庄附件球场，通过关键词+Hexo静态页面 Mvp51 设计图效果 附近球场、球友、球队功能支持","categories":[],"tags":[{"name":"计划","slug":"计划","permalink":"http://localhost:4000/tags/计划/"}]},{"title":"Hexo工作原理","slug":"Hexo如何工作","date":"2018-05-24T01:18:22.000Z","updated":"2018-05-24T01:27:54.140Z","comments":true,"path":"2018/05/24/Hexo如何工作/","link":"","permalink":"http://localhost:4000/2018/05/24/Hexo如何工作/","excerpt":"","text":"你可能用过hexo(或者jekyll)来搭建自己的博客网站。通常我们在安装、配置完成hexo之后，借助hexo，一般通过以下步骤，就可以完成一篇博客的编写及发布，真是方便极了： |$ hexo init // 创建一个新的hexo项目$ hexo new mynewblog // 新建一篇标题为mynewblog的文章$ hexo server // 为hexo在本地起一个http server, 然后通过浏览器访问博客$ hexo generate // 生成将要发布的博客网站包含html在内的静态资源$ hexo deploy // 将generate的结果发布到_config.yml中指定的仓库 | 可是，从hexo init到hexo deploy中间发生了什么呢？为了搞清楚这一过程、理解hexo的工作原理，本文将试着回答以下问题: 命令行中的hexo是什么 hexo是怎么将我们写好的markdown转换成html的 hexo插件是如何工作的 本地的hexo项目和git page有什么关系 本文不是: hexo的安装、使用教程 git page的使用教程 命令行中的hexo是什么?hexo项目在github上已经有超过17k的star了，但是你知道吗，日常我们在命令行”操作”hexo时所输入的hexo(例如hexo init)并不是这个17k个star的项目! 是的，我们在命令行中所输入的”hexo”实际是hexo-cli项目，该项目在github上的star还不足50个。 hexo可以粗略分为三个子项目，分别是: hexo-cli hexo (下文中用hexo core来指代) hexo plugins 其中hexo plugins不是指某一个单独的项目，而是泛指所有的hexo plugin项目。 请看下图:让我们结合这张图来大致看看这三个项目的作用(下面的链接均是指向Github中相关的源码): hexo-cli: hexo命令行项目，作用是: 启动hexo命令(进程)，及其参数解析机制。每次我们输入’hexo xxx’命令后，都会通过node调用hexo-cli中的entry函数(比如，可以把’hexo init’视为’node hexo-cli/entry.js init’) 实现hexo命令的三个初始参数(功能): init / version / help 加载hexo核心模块，并初始化 hexo core: hexo核心，他的主要作用如下: 实现了hexo功能扩展对象 实现了hexo核心功能, 如new, publish, generate等（其实是一些hexo插件，下文中会详细分析） hexo plugins: 指一些能够扩展hexo的插件。插件可以按功能分成两类: 扩展hexo命令的参数，如hexo-server(安装这个插件以后才能使用hexo server命令) 扩展hexo解析文件的”能力”，如增加jade模版解析功能的hexo-render-jade插件 从markdown到html的旅程简单来说，hexo中，从markdown到html的generate过程中做了两件事： 模板渲染 模板渲染 是的，就是这样，就是两次模板渲染。只不过两次渲染的输入、渲染模板的引擎、输出不一样。此处应该有一个表格：还得有一张图: 对上面表格和图的说明: hexo core在generate的过程中会产生一个对象，我们在这里把这个对象称为article。第一次渲染的主要目的就是给这个对象添加title,content等属性。其中: article.title, article.date, article.tags, article.categories等属性来自yml front的部分 article.content是markdown文章解析后的html片段 hexo项目目录下包含三个子目录， source目录，写博客的主要工作目录。这个目录下存放的是我们的markdown文章以及js, images, css themes目录，主题目录，定义了即将生成的html的layout, 和html中需要加载的css, js, images public目录, hexo generate的最终输出目录。里面包含了整个博客网站的html, css, js, images 第二次渲染，需要引入对应模板文件格式的插件，如.ejs文件就需要使用hexo-render-ejs插件，.jade文件需要使用hexo-render-jade插件，而.sass文件则需要hexo-render-sass插件来转换成css文件。hexo的这一设计有点类似webpack中的loader。 hexo插件是如何工作的hexo和webpack还有一点类似的地方就是插件驱动理念。即hexo(和webpack)是先实现一套(插件)扩展系统，然后再往扩展系统中添加插件来实现自身的功能。即我们日常使用的hexo init, hexo new，hexo generate等等功能都是通过一个个插件(其实就是一个个function)实现的。 具体来讲就是: hexo.extend这个对象的每个属性都是一个用来绑定(特定)插件的对象。（所谓”绑定”，其实就是对象的register方法） hexo初始化过程中先加载内部插件，再加载外部插件 而这些插件的功能分为两大类: 命令行插件和generate过程相关功能，例如： 命令行插件, hexo new, 是在hexo.extend.console对象上绑定的一个插件 generate过程相关的插件，如上文提到的往article对象添加title,content等属性的功能，是通过往hexo.extend.processer对象上绑定post插件来实现的 所以，当我们想自己动手写插件时，就是像hexo官网给出的这样,调用某个对象的register方法，如hexo.extend.console.register。 hexo和git page 如上图，(用户通过浏览器访问到的)git page上的博客网站其实是hexo generate之后生成的public目录下的内容。 所以，一个hexo博客项目应该有两个仓库: (基于hexo init结果的)博客编写仓库。可以把这个项目看成一个代码库，用来”开发”博客网站(包含写博客，生成博客等任务) 存放(hexo generate结果的)public目录仓库。这个项目是”只读”的，我们不会直接修改这个仓库的内容，我们也不会对这个仓库直接进行git pull、git commit、git push等常规操作。这个仓库的内容就是public目下的内容，即是通过hexo generate产生、hexo deploy提交的。 总结hexo简洁、强大的功能来自于自身优雅的系统设计: hexo进程启动、hexo核心对象封装、插件系统分别独立 自身采用插件驱动，生来就具备高可扩展性 文章转载于hexo是怎么工作的","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://localhost:4000/tags/Hexo/"}]},{"title":"Windows Git安装环境配置","slug":"Windows Git安装环境配置","date":"2018-05-23T08:10:42.000Z","updated":"2018-05-25T02:01:21.329Z","comments":true,"path":"2018/05/23/Windows Git安装环境配置/","link":"","permalink":"http://localhost:4000/2018/05/23/Windows Git安装环境配置/","excerpt":"","text":"世上无难事只怕有心人！ 下载安装 从Git官网下载Windows安装包，官网地址 点我 参考https://blog.csdn.net/dietime1943/article/details/71751007安装 环境变量配置环境变量Path 或者 直接使用 git-bash.exeD:\\Program Files\\Git\\cmd Git常用命令简单命令# 版本查看$ git --versiongit version 2.17.0.windows.1 新建代码库# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 配置# 显示当前Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name \"[name]\"$ git config [--global] user.email \"[email address]\" 增加删除文件# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2]# 停止追踪指定文件，但该文件会保留在工作区$ git rm -cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 代码提交# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库$ git commit -a # 提交时显示所有diff信息$ git commit -v # 使用一次新的commit，代替上一次提交# 如果代码没有任何变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit, 并包括指定文件的新变化$ git commit --amend [file1] [file2] 分支# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]$ 删除远程分支$ git push origin -delete [branch-name]$ git branch -dr [remote/branch] Git原理Workspace：工作区Index / Stage：暂存区Repository：仓库区（或本地仓库）Remote：远程仓库 相关链接阮一峰常用 Git 命令清单","categories":[],"tags":[{"name":"windows","slug":"windows","permalink":"http://localhost:4000/tags/windows/"},{"name":"git","slug":"git","permalink":"http://localhost:4000/tags/git/"}]},{"title":"Hexo搭建博客","slug":"Hexo搭建博客","date":"2018-05-23T01:37:40.000Z","updated":"2018-05-24T01:21:52.084Z","comments":true,"path":"2018/05/23/Hexo搭建博客/","link":"","permalink":"http://localhost:4000/2018/05/23/Hexo搭建博客/","excerpt":"","text":"零基础搭建个人博客（Hexo + Git）","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://localhost:4000/tags/Hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-05-22T07:29:40.327Z","updated":"2018-05-24T01:57:38.791Z","comments":true,"path":"2018/05/22/hello-world/","link":"","permalink":"http://localhost:4000/2018/05/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://localhost:4000/tags/Hexo/"}]}]}